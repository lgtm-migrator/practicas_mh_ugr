<h1 id="descripci√≥n-del-problema">Descripci√≥n del problema</h1>
<p>El problema del Aprendizaje de Pesos en Caracter√≠sticas (APC) es un problema de b√∫squeda de codificaci√≥n real (<span class="math inline"><em>s</em><em>o</em><em>l</em>‚ÄÑ‚àà‚ÄÑ‚Ñù<sup><em>n</em></sup></span>). Consiste en encontrar un vector de pesos que pondere las caracter√≠sticas asociadas a un modelo. En este caso utilizamos un modelo no param√©trico llamado KNN. La ponderaci√≥n se realiza multiplicando cada caracter√≠stica por su valor correspondiente dentro del vector de pesos. Es decir, teniendo unos datos de entrada <span class="math inline"><em>X</em>‚ÄÑ‚àà‚ÄÑ‚Ñù<sup><em>m</em>‚ÄÖ√ó‚ÄÖ<em>n</em></sup></span> y un vector de pesos <span class="math inline"><em>w‚Éó</em>‚ÄÑ=‚ÄÑ(<em>w</em><sub>1</sub>,‚ÄÜ<em>w</em><sub>2</sub>,‚ÄÜ...,‚ÄÜ<em>w</em><sub><em>n</em></sub>)<sup><em>T</em></sup>‚ÄÑ‚àà‚ÄÑ‚Ñù<sup><em>n</em></sup></span>, multiplicamos cada columna por la componente correspondiente para obtener <span class="math inline"><em>X</em>‚Ä≤</span>.</p>
<p>La ponderaci√≥n se realiza para obtener un balance √≥ptimo entre precisi√≥n (o cualquier otra m√©trica que eval√∫e el modelo) y sencillez. La sencillez se consigue al eliminar ciertas caracter√≠sticas cuyo peso est√° por debajo de un umbral, en nuestro caso, <span class="math inline">0.2</span>, ya que nos aseguramos que no son demasiado relevantes para las predicciones. Un modelo no param√©trico como es el caso de KNN tiene la desventaja de que es costoso hacer predicciones mientras que el tiempo de ‚Äúfitting‚Äù es casi nulo. Por ese motivo es importante mantener √∫nicamente las caracter√≠sticas relevantes para obtener un modelo eficiente. Adem√°s, reducimos el riesgo de sobreajuste ya que obtenemos una funci√≥n hip√≥tesis m√°s sencilla y menos sensible al ruido.</p>
<p>Para este problema vamos a utilizar dos m√©todos de validaci√≥n. El primero, un algoritmo de validaci√≥n cruzada llamado k-fold, que consiste en dividir el conjunto de entrenamiento en K particiones disjuntas, ajustar el modelo con <span class="math inline"><em>K</em>‚ÄÖ‚àí‚ÄÖ1</span> particiones y validarlo con la partici√≥n restante. El proceso se repite con todas las combinaciones posibles (K combinaciones). En nuestro caso usamos <span class="math inline"><em>K</em>‚ÄÑ=‚ÄÑ5</span>, es decir <strong>5-fold cross validation</strong>.</p>
<p>El segundo algoritmo se utiliza para evaluar las soluciones en cada paso de un algoritmo de b√∫squeda. Lo que se conoce com√∫nmente como la funci√≥n fitness o la funci√≥n objetivo. Para ese caso calculamos la precision con Leave-One-Out que consiste en usar el mismo conjunto de datos tanto para prueba como para validaci√≥n pero eliminando la muestra en cuesti√≥n antes de predecir para evitar una precisi√≥n err√≥nea del 100%.</p>
<p>Con esto aclarado, podemos definir el marco de trabajo principal de este proyecto, la funci√≥n fitness u objetivo y el modelo a utilizar:</p>
<p><br /><span class="math display"><em>f</em>(<em>w‚Éó</em>)‚ÄÑ=‚ÄÑ<em>Œ±</em>‚ÄÖ√ó‚ÄÖ<em>p</em><em>r</em><em>e</em><em>c</em><em>i</em><em>s</em><em>i</em><em>o</em><em>n</em>(<em>w‚Éó</em>,‚ÄÜ<em>X</em>)‚ÄÖ+‚ÄÖ(1‚ÄÖ‚àí‚ÄÖ<em>Œ±</em>)‚ÄÖ√ó‚ÄÖ<em>r</em><em>e</em><em>d</em><em>u</em><em>c</em><em>c</em><em>i</em><em>o</em><em>n</em>(<em>w‚Éó</em>)</span><br /></p>
<p>Donde: <br /><span class="math display">$$
reduccion(\vec{w}) = \frac{\text{n¬∫ de componentes &lt; umbral}}{\text{n¬∫ de componentes total}}$$</span><br /> <br /><span class="math display">$$precision(\vec{w}, X) = \frac{\text{predicciones correctas ponderando con } \vec{w}}{\text{predicciones totales}}$$</span><br /></p>
<p>Para reducir el coste computacional de los algoritmos, vamos a utilizar el clasificador KNN m√°s sencillo usando un solo vecino. Por tanto, para hacer una predicci√≥n basta con hallar la clase del vecino m√°s cercano. Se puede utilizar cualquier medida de distancia, en nuestro caso usamos la eucl√≠dea <span class="math inline">‚Ñì<sub>2</sub></span> o <span class="math inline">‚Ñì<sub>2</sub><sup>2</sup></span>:</p>
<p><br /><span class="math display">$$vecino(\vec{x}) = \underset{\vec{v} \in X}{\operatorname{argmin}} \ distancia(\vec{x}, \vec{v})$$</span><br /></p>
<h1 id="descripci√≥n-de-la-aplicaci√≥n-de-los-algoritmos">Descripci√≥n de la aplicaci√≥n de los algoritmos</h1>
<p>Las soluciones a nuestro problema se representan con un vector de pesos <span class="math inline"><em>w‚Éó</em>‚ÄÑ=‚ÄÑ(<em>w</em><sub>1</sub>,‚ÄÜ<em>w</em><sub>2</sub>,‚ÄÜ...,‚ÄÜ<em>w</em><sub><em>n</em></sub>)<sup><em>T</em></sup>‚ÄÑ‚àà‚ÄÑ[0,‚ÄÜ1]<sup><em>n</em></sup></span>. Por tanto, tenemos que cada componente <span class="math inline"><em>w</em><sub><em>i</em></sub></span> pondera una caracter√≠stica distinta. Como podemos intuir, caracter√≠sticas con un peso pr√≥ximo a 1 son relevantes para el c√°lculo de la distancia en KNN mientras que las que tienen un peso pr√≥ximo a 0 son pr√°cticamente irrelevantes.</p>
<p>Matem√°ticamente, la ponderaci√≥n de pesos podemos verla como una transformaci√≥n lineal<br />
<span class="math inline"><em>T</em>‚ÄÑ:‚ÄÑ‚Ñù<sup><em>n</em></sup>‚ÄÑ‚Üí‚ÄÑ‚Ñù<sup><em>n</em></sup>,‚ÄÜ<em>T</em>(<em>x‚Éó</em>)‚ÄÑ=‚ÄÑ(<em>w</em><sub>1</sub><em>x</em><sub><em>i</em></sub>,‚ÄÜ<em>w</em><sub>2</sub><em>x</em><sub>2</sub>,‚ÄÜ...,‚ÄÜ<em>w</em><sub><em>n</em></sub><em>x</em><sub><em>n</em></sub>)<sup><em>T</em></sup></span>. Claramente podemos ver la matriz asociada a esta aplicaci√≥n lineal es la siguiente:</p>
<p><br /><span class="math display">$$M_T =
\begin{bmatrix}
    w_1 &amp; 0 &amp; \dots  &amp; 0 \\
    0 &amp; w_{2} &amp; \dots &amp; 0 \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    0 &amp; 0 &amp; \dots  &amp; w_{n}
\end{bmatrix}
$$</span><br /></p>
<p>Esta forma de ver la ponderaci√≥n es importante a la hora de implementarla, ya que podemos utilizar cualquier biblioteca de c√°lculo matricial como BLAS o LAPACK para realizar los c√°lculos de forma eficiente. Incluso m√°s eficiente que multiplicar cada columna de la matriz de datos por su peso correspondiente. Dichas bibliotecas suelen usar instrucciones m√°quina √≥ptimas y algoritmos paralelos.</p>
<p>Una vez sabemos como transformar los datos, podemos evaluar diferentes algoritmos o soluciones. La forma de evaluar cada algoritmo es siempre la misma:</p>
<ol type="1">
<li>Dividimos el conjunto en 5 particiones disjuntas</li>
<li>Para cada partici√≥n:
<ol type="1">
<li>Calculamos los pesos usando el algoritmo en cuesti√≥n con las particiones restantes</li>
<li>Transformamos los datos tanto de entrenamiento como de prueba con los pesos obtenidos.</li>
<li>Entrenamos un clasificador KNN con los datos de entrenamiento transformados.</li>
<li>Evaluamos el modelo con el conjunto de prueba transformado (la partici√≥n).</li>
</ol></li>
</ol>
<h2 id="knn">KNN</h2>
<p>Nuestro clasificador es bastante sencillo de implementar. El pseudoc√≥digo es el siguiente:</p>
<div class="sourceCode" id="cb1" data-caption="Pseudoc√≥digo del clasificador KNN"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb1-1" title="1"><span class="kw">function</span> KNN(x, X, y)</a>
<a class="sourceLine" id="cb1-2" title="2">  kdtree = build_KDTree(X)</a>
<a class="sourceLine" id="cb1-3" title="3">  nearest_neighbour = KDTree.query(x, k=<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1-4" title="4">  return y[nearest_neighbour]</a></code></pre></div>
<p>Como se puede observar, se utiliza una √°rbol KDTree para encontrar el vecino m√°s cercano. Para los conjuntos de datos que estamos utilizando parece una opci√≥n sensata comparada con el t√≠pico algoritmo de fuerza bruta. La complejidad temporal de estos arboles son de <span class="math inline"><em>O</em>(<em>n</em>)</span> para construirlos y <span class="math inline"><em>O</em>(<em>l</em><em>o</em><em>g</em>(<em>n</em>))</span> hasta <span class="math inline"><em>O</em>(<em>n</em>)</span> en el peor de los casos para consultarlos. Mientras que el algoritmo de fuerza bruta es <span class="math inline"><em>O</em>(<em>n</em>)</span> para cada consulta. Si construimos un solo √°rbol y realizamos muchas consultas, da un mejor rendimiento que fuerza bruta. <strong>Nota</strong>: Suponemos que el KDTree al hacer una consulta devuelve un vector de √≠ndices correspondiente a los k vecinos m√°s cercanos.</p>
<h2 id="evaluacion">Evaluacion</h2>
<p>Para evaluar nuestra soluci√≥n en las diferentes iteraciones de un algoritmo de b√∫squeda o una vez entrenado el modelo, se utiliza la siguiente funci√≥n objetivo:</p>
<p><br /><span class="math display"><em>f</em>(<em>w‚Éó</em>)‚ÄÑ=‚ÄÑ<em>Œ±</em>‚ÄÖ√ó‚ÄÖ<em>p</em><em>r</em><em>e</em><em>c</em><em>i</em><em>s</em><em>i</em><em>o</em><em>n</em>(<em>w‚Éó</em>,‚ÄÜ<em>X</em>)‚ÄÖ+‚ÄÖ(1‚ÄÖ‚àí‚ÄÖ<em>Œ±</em>)‚ÄÖ√ó‚ÄÖ<em>r</em><em>e</em><em>d</em><em>u</em><em>c</em><em>c</em><em>i</em><em>o</em><em>n</em>(<em>w‚Éó</em>)</span><br /></p>
<p>Como hemos visto anteriormente, la precisi√≥n indicar√≠a que tan bueno es el clasificador KNN de un vecino cuando ponderamos con el vector de pesos <span class="math inline"><em>W‚Éó</em></span>. La precisi√≥n se calcula de dos formas distintas dependiendo de cuando se eval√∫a.</p>
<p>Si se eval√∫a con √∫nicamente los datos de entrenamiento, como es el caso para la b√∫squeda local o los algoritmos gen√©ticos, se utiliza el m√©todo Leave-One-Out comentado anteriormente:</p>
<div class="sourceCode" id="cb2" data-caption="Pseudoc√≥digo de la validaci√≥n Leave-One-Out"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">function</span> accuracy_leave_one_out(X_train, y_train)</a>
<a class="sourceLine" id="cb2-2" title="2">  kdtree = build_KDTree(X)</a>
<a class="sourceLine" id="cb2-3" title="3">  accuracy = <span class="dv">0</span></a>
<a class="sourceLine" id="cb2-4" title="4">  <span class="kw">for</span> x <span class="kw">in</span> rows(X_train):</a>
<a class="sourceLine" id="cb2-5" title="5">    <span class="co">// Cogemos el segundo m√°s cercano porque el primero es √©l mismo.</span></a>
<a class="sourceLine" id="cb2-6" title="6">    nearest_neighbour = KDTree.query(x, k=<span class="dv">2</span>)[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb2-7" title="7">    <span class="kw">if</span> y_train[nearest_neighbour] == y_train[x.index] <span class="kw">then</span></a>
<a class="sourceLine" id="cb2-8" title="8">      accuracy = accuracy + <span class="dv">1</span></a>
<a class="sourceLine" id="cb2-9" title="9">  return accuracy / num_rows(X_train)</a></code></pre></div>
<p>Si se eval√∫a una vez entrenado el modelo con el conjunto de entrenamiento, se utiliza el conjunto de test para calcular la precision.</p>
<div class="sourceCode" id="cb3" data-caption="Pseudoc√≥digo de la validaci√≥n Hold-out"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb3-1" title="1"><span class="kw">function</span> accuracy_test(X_train, y_train, X_test, y_test)</a>
<a class="sourceLine" id="cb3-2" title="2">  accuracy = <span class="dv">0</span></a>
<a class="sourceLine" id="cb3-3" title="3">  <span class="kw">for</span> x <span class="kw">in</span> rows(X_test):</a>
<a class="sourceLine" id="cb3-4" title="4">    prediction = KNN(x, X_train, y_train)</a>
<a class="sourceLine" id="cb3-5" title="5">    <span class="kw">if</span> prediction == y_test[x.index] <span class="kw">then</span></a>
<a class="sourceLine" id="cb3-6" title="6">      accuracy = accuracy + <span class="dv">1</span></a>
<a class="sourceLine" id="cb3-7" title="7">  return accuracy / num_rows(X_test)</a></code></pre></div>
<p>Como hemos visto anteriormente, cualquier vector de pesos <span class="math inline"><em>w‚Éó</em>‚ÄÑ‚àà‚ÄÑ‚Ñù<sup><em>d</em></sup></span> no es una soluci√≥n v√°lida. Cada componente debe estar en el intervalo <span class="math inline">[0,‚ÄÜ1]</span> por tanto, es posible que sea necesario capar algunas soluciones. Para ello se puede usar el siguiente algoritmo</p>
<div class="sourceCode" id="cb4" data-caption="Pseudoc√≥digo de la funci√≥n clip"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb4-1" title="1"><span class="kw">function</span> clip(w)</a>
<a class="sourceLine" id="cb4-2" title="2">  <span class="kw">for</span> w_i <span class="kw">in</span> components(w):</a>
<a class="sourceLine" id="cb4-3" title="3">    <span class="kw">if</span> w_i &lt; <span class="dv">0</span> <span class="kw">then</span>; w_i = <span class="dv">0</span></a>
<a class="sourceLine" id="cb4-4" title="4">    <span class="kw">if</span> w_i &gt; <span class="dv">1</span> <span class="kw">then</span>; w_i = <span class="dv">1</span></a>
<a class="sourceLine" id="cb4-5" title="5">  return w</a></code></pre></div>
<h1 id="pseudoc√≥digo-de-los-algoritmos">Pseudoc√≥digo de los algoritmos</h1>
<h2 id="b√∫squeda-local">B√∫squeda Local</h2>
<p>La b√∫squeda local ya supone un algoritmo m√°s complejo. En nuestro caso utilizamos la b√∫squeda local del primero mejor, es decir, actualizamos la soluci√≥n con el primer vecino que tenga un fitness mayor. La generaci√≥n de cada vecino se realiza mutando una componente aleatoria sin repetici√≥n. Esta mutaci√≥n es simplemente sumar un valor aleatorio de una distribuci√≥n gaussiana <span class="math inline">ùí©(0,‚ÄÜ<em>œÉ</em><sup>2</sup>)</span>. Donde sigma es 0.3 para nuestro caso. El vector de pesos adem√°s se inicializa aleatoriamente: <span class="math inline"><em>w‚Éó</em>‚ÄÑ=‚ÄÑ(<em>w</em><sub>0</sub>,‚ÄÜ<em>w</em><sub>1</sub>,‚ÄÜ...,‚ÄÜ<em>w</em><sub><em>n</em></sub>)<sup><em>T</em></sup></span> donde <span class="math inline"><em>w</em><sub><em>i</em></sub>‚ÄÑ‚àº‚ÄÑùí∞(0,‚ÄÜ1)</span></p>
<p>El algoritmo se detiene cuando generamos 15000 vecinos o cuando no se produce mejora tras generar <span class="math inline">20<em>n</em></span> vecinos, donde <span class="math inline"><em>n</em></span> es el n√∫mero de caracter√≠sticas de nuestro conjunto de datos.</p>
<div class="sourceCode" id="cb5" data-caption="Pseudoc√≥digo del algoritmo de B√∫squeda Local"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb5-1" title="1"><span class="kw">function</span> local_search(X, y, max_neighbours, sigma, seed):</a>
<a class="sourceLine" id="cb5-2" title="2">    n_features = num_columns(X)</a>
<a class="sourceLine" id="cb5-3" title="3">    feed_random_generator(seed)</a>
<a class="sourceLine" id="cb5-4" title="4">    weights = generate_random_uniform_vector(n_features, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb5-5" title="5">    fitness = evaluate(weights, X, y)</a>
<a class="sourceLine" id="cb5-6" title="6">    n_generated = <span class="dv">0</span></a>
<a class="sourceLine" id="cb5-7" title="7">    last_improvement = <span class="dv">0</span></a>
<a class="sourceLine" id="cb5-8" title="8">    <span class="kw">while</span> n_generated &lt; max_neighbours:</a>
<a class="sourceLine" id="cb5-9" title="9">        w_prime = copy(weights)</a>
<a class="sourceLine" id="cb5-10" title="10">        <span class="kw">for</span> k <span class="kw">in</span> permutation(n_features):</a>
<a class="sourceLine" id="cb5-11" title="11">            n_generated += <span class="dv">1</span></a>
<a class="sourceLine" id="cb5-12" title="12">            last_state = w_prime[k]</a>
<a class="sourceLine" id="cb5-13" title="13">            w_prime[k] += generate_gaussian(<span class="dv">0</span>, sigma)</a>
<a class="sourceLine" id="cb5-14" title="14">            w_prime = clip(w_prime)</a>
<a class="sourceLine" id="cb5-15" title="15">            f = evaluate(w_prime, X, y)</a>
<a class="sourceLine" id="cb5-16" title="16">            <span class="kw">if</span> fitness &lt; f <span class="kw">then</span></a>
<a class="sourceLine" id="cb5-17" title="17">                weights = w_prime</a>
<a class="sourceLine" id="cb5-18" title="18">                fitness = f</a>
<a class="sourceLine" id="cb5-19" title="19">                last_improvement = n_generated</a>
<a class="sourceLine" id="cb5-20" title="20">                <span class="kw">break</span></a>
<a class="sourceLine" id="cb5-21" title="21">            <span class="kw">else</span> <span class="kw">then</span></a>
<a class="sourceLine" id="cb5-22" title="22">              w_prime[k] = last_state</a>
<a class="sourceLine" id="cb5-23" title="23">            diff = n_generated - last_improvement</a>
<a class="sourceLine" id="cb5-24" title="24">            <span class="kw">if</span> n_generated &gt; max_neighbours <span class="kw">or</span> diff &gt; (<span class="dv">20</span> * n_features):</a>
<a class="sourceLine" id="cb5-25" title="25">                return weights</a>
<a class="sourceLine" id="cb5-26" title="26">    return weights</a></code></pre></div>
<p>La funci√≥n <em>evaluate</em> utilizada en el algoritmo √∫nicamente transforma los datos con los pesos correspondientes y calcula el fitness de la soluci√≥n.</p>
<div class="sourceCode" id="cb6" data-caption="Pseudoc√≥digo del la funci√≥n evaluadora de soluciones para B√∫squeda Local"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb6-1" title="1"><span class="kw">function</span> evaluate(weights, X, y):</a>
<a class="sourceLine" id="cb6-2" title="2">    <span class="co">// Aplicar la ponderaci√≥n y eliminar las caracter√≠sticas</span></a>
<a class="sourceLine" id="cb6-3" title="3">    <span class="co">// con un peso menor a 0.2</span></a>
<a class="sourceLine" id="cb6-4" title="4">    X_transformed = transform(weights, X)</a>
<a class="sourceLine" id="cb6-5" title="5">    accuracy = knn_accuracy_leave_one_out(X_transformed, y)</a>
<a class="sourceLine" id="cb6-6" title="6">    return fitness(weights, accuracy)</a></code></pre></div>
<div class="sourceCode" id="cb7" data-caption="Pseudoc√≥digo del la funci√≥n fitness"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb7-1" title="1"><span class="kw">function</span> fitness(weights, accuracy, alpha=<span class="dv">0.5</span>, threshold=<span class="dv">0.2</span>):</a>
<a class="sourceLine" id="cb7-2" title="2">    reduction = count(weights &lt; threshold) / length(weights)</a>
<a class="sourceLine" id="cb7-3" title="3">    return alpha * accuracy + (<span class="dv">1</span> - alpha) * reduction</a></code></pre></div>
<h2 id="algoritmos-gen√©ticos">Algoritmos gen√©ticos</h2>
<p>Para el desarrollo de la segunda pr√°ctica se ha implementado varios algoritmos evolutivos, entre ellos, algoritmos gen√©ticos. Para el desarrollo de estos algoritmos se han tenido que dise√±ar diferentes funciones que las podemos clasificar en <em>operadores</em> y en funciones relacionadas con la <em>estrategia evolutiva</em>.</p>
<h3 id="operadores">Operadores</h3>
<h4 id="selecci√≥n">Selecci√≥n</h4>
<p>El primer operador implementado es el operador de selecci√≥n. Para todos los algoritmos evolutivos utilizamos el mismo operador, <strong>torneo binario</strong>. Este operador selecciona los mejores individuos a partir de una serie de torneos aleatorios realizados en parejas de dos individuos. Es decir, se seleccionan dos individuos aleatoriamente y el mejor de los dos se introduce en la nueva poblaci√≥n. Este proceso se repite tantas veces como el n√∫mero de individuos vayamos a seleccionar para la poblaci√≥n descendiente.</p>
<div class="sourceCode" id="cb8" data-caption="Pseudoc√≥digo del operador de selecci√≥n"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb8-1" title="1"><span class="kw">function</span> binaryTournament(individuals, num_selected):</a>
<a class="sourceLine" id="cb8-2" title="2">    chosen = []</a>
<a class="sourceLine" id="cb8-3" title="3">    <span class="kw">for</span> i = <span class="dv">0</span>...num_selected <span class="kw">do</span></a>
<a class="sourceLine" id="cb8-4" title="4">        aspirants = selectRandomly(individuals, <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb8-5" title="5">        <span class="co">// A√±ade el mejor de los dos seleccionados</span></a>
<a class="sourceLine" id="cb8-6" title="6">        chosen.append(max(aspirants, by=fitness_value)) </a>
<a class="sourceLine" id="cb8-7" title="7">    return chosen</a></code></pre></div>
<h4 id="cruce">Cruce</h4>
<p>Para el operador de cruce hemos implementado dos opciones distintas. El operador BLX-Alpha y el operador Aritm√©tico. Para el caso del primero hemos usado un Alpha de 0.3.</p>
<div class="sourceCode" id="cb9" data-caption="Pseudoc√≥digo de los operadores de cruce"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb9-1" title="1"><span class="kw">function</span> cx_arithmetic(ind1, ind2):</a>
<a class="sourceLine" id="cb9-2" title="2">    alphas = random_vector(len(ind1))</a>
<a class="sourceLine" id="cb9-3" title="3">    c1 = (<span class="dv">1</span> - alphas) * ind1 + alphas * ind2</a>
<a class="sourceLine" id="cb9-4" title="4">    c2 = alphas * ind1 + (<span class="dv">1</span> - alphas) * ind2</a>
<a class="sourceLine" id="cb9-5" title="5">    return c1, c2</a>
<a class="sourceLine" id="cb9-6" title="6"></a>
<a class="sourceLine" id="cb9-7" title="7"></a>
<a class="sourceLine" id="cb9-8" title="8"><span class="kw">function</span> cx_blx(ind1, ind2, alpha):</a>
<a class="sourceLine" id="cb9-9" title="9">    c_max = max(ind1, ind2) <span class="co">// El m√°ximo componente a componente</span></a>
<a class="sourceLine" id="cb9-10" title="10">    c_min = min(ind1, ind2) <span class="co">// El m√≠nimo componente a componente</span></a>
<a class="sourceLine" id="cb9-11" title="11">    inteval = c_max - c_min</a>
<a class="sourceLine" id="cb9-12" title="12">    c1 = uniform_vector(c_min - inteval * alpha,</a>
<a class="sourceLine" id="cb9-13" title="13">                        c_max + inteval * alpha)</a>
<a class="sourceLine" id="cb9-14" title="14">    c2 = uniform_vector(c_min - inteval * alpha,</a>
<a class="sourceLine" id="cb9-15" title="15">                        c_max + inteval * alpha)</a>
<a class="sourceLine" id="cb9-16" title="16">    c1 = clip(c1, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb9-17" title="17">    c2 = clip(c2, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb9-18" title="18">    return c1, c2</a></code></pre></div>
<h4 id="mutaci√≥n">Mutaci√≥n</h4>
<p>Para el operador de mutaci√≥n hemos usado el mismo que para B√∫squeda Local, el operador de mutaci√≥n gaussiano. El cual ha sido modificado para a√±adir la probabilidad de mutaci√≥n y para devolver un booleano que indica si se ha realizado la mutaci√≥n o no. Esto evita recalcular las funciones fitness sobre individuos que no han mutado.</p>
<div class="sourceCode" id="cb10" data-caption="Pseudoc√≥digo del operador de mutaci√≥n"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb10-1" title="1">def mut_gaussian(individual, mu, sigma, indpb):</a>
<a class="sourceLine" id="cb10-2" title="2">    size = len(individual)</a>
<a class="sourceLine" id="cb10-3" title="3">    mutated = <span class="kw">False</span></a>
<a class="sourceLine" id="cb10-4" title="4">    <span class="kw">for</span> i <span class="kw">in</span> range(size):</a>
<a class="sourceLine" id="cb10-5" title="5">        <span class="kw">if</span> random() &lt; indpb:</a>
<a class="sourceLine" id="cb10-6" title="6">            mutated = <span class="kw">True</span></a>
<a class="sourceLine" id="cb10-7" title="7">            individual[i] += random_gaussian(mu, sigma)</a>
<a class="sourceLine" id="cb10-8" title="8">            <span class="kw">if</span> individual[i] &gt; <span class="dv">1</span>:</a>
<a class="sourceLine" id="cb10-9" title="9">                individual[i] = <span class="dv">1</span></a>
<a class="sourceLine" id="cb10-10" title="10">            elif individual[i] &lt; <span class="dv">0</span>:</a>
<a class="sourceLine" id="cb10-11" title="11">                individual[i] = <span class="dv">0</span></a>
<a class="sourceLine" id="cb10-12" title="12">    return individual, mutated</a></code></pre></div>
<h3 id="estrategias">Estrategias</h3>
<p>En esta secci√≥n se encuentra aquellas funciones relacionadas con la estrategia evolutiva de los algoritmos. Existen dos estrategias principales que son, la estrategia generacional y estrategia estacionaria. La primera genera una poblaci√≥n del mismo tama√±o que la de los padres, y se emplea un reemplazamiento elitista para conservar el mejor de la anterior poblaci√≥n. Para la segunda se generan √∫nicamente dos descendientes que compiten con los dos peores de la poblaci√≥n actual. Las funciones utilizadas para estas estrategias son las siguientes:</p>
<div class="sourceCode" id="cb11" data-caption="Pseudoc√≥digo de la ejecuci√≥n de un un algoritmo evolutido "><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb11-1" title="1"><span class="kw">function</span> run(population_size, max_evaluations, cxpb, mupb,</a>
<a class="sourceLine" id="cb11-2" title="2">              generational=<span class="kw">True</span>, mem_strategy=None):</a>
<a class="sourceLine" id="cb11-3" title="3">    hof = HallOfFame(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb11-4" title="4">    pop = create_population(n=population_size)</a>
<a class="sourceLine" id="cb11-5" title="5">    num_generations = <span class="dv">0</span></a>
<a class="sourceLine" id="cb11-6" title="6">    num_evaluations = evaluate_population(pop)</a>
<a class="sourceLine" id="cb11-7" title="7">    hof.update(pop)</a>
<a class="sourceLine" id="cb11-8" title="8">    trace = []</a>
<a class="sourceLine" id="cb11-9" title="9">    step_func = generational_step <span class="kw">if</span> generational <span class="kw">else</span> stationary_step</a>
<a class="sourceLine" id="cb11-10" title="10">    <span class="kw">while</span> num_evaluations &lt; max_evaluations:</a>
<a class="sourceLine" id="cb11-11" title="11">        num_generations += <span class="dv">1</span></a>
<a class="sourceLine" id="cb11-12" title="12">        num_evaluations += step_func(pop, cxpb, mupb,</a>
<a class="sourceLine" id="cb11-13" title="13">                                     mem_strategy, num_generations)</a>
<a class="sourceLine" id="cb11-14" title="14">        hof.update(pop)</a>
<a class="sourceLine" id="cb11-15" title="15">        trace.append(hof[<span class="dv">0</span>].fitness.values[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb11-16" title="16">    return hof[<span class="dv">0</span>], trace</a></code></pre></div>
<p>Esta es la funci√≥n que se encarga de ejecutar el algoritmo evolutivo. Es una funci√≥n gen√©rica que recibe el tama√±o de poblaci√≥n inicial, n√∫mero m√°ximo de evaluaciones de la funci√≥n fitness y las estrategias a emplear. Con esta funci√≥n se pueden ejecutar tanto algoritmos gen√©ticos (estacionarios y generacionales) como los algoritmos mem√©ticos explicados m√°s adelante.</p>
<p>Como se puede observar, esta funci√≥n lo √∫nico que hace es ejecutar la estrategia evolutiva que corresponda, hasta alcanzar el n√∫mero m√°ximo de evaluaciones. Mientras, en cada paso se almacena el mejor individuo encontrado hasta el momento, usando un objeto ‚ÄúHallOfFame‚Äù que representa una lista ordenada (por fitness) de individuos. Finalmente se devuelve dicho individuo y una traza del valor fitness del mejor individuo de cada generaci√≥n.</p>
<p>En cada paso del algoritmo anterior se llama a las siguientes funciones:</p>
<div class="sourceCode" id="cb12" data-caption="Pseudoc√≥digo los esquemas de evoluci√≥n"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb12-1" title="1"><span class="kw">function</span> generational_step(pop, cxpb, mupb, mem_strategy, num_generations):</a>
<a class="sourceLine" id="cb12-2" title="2">    offspring = binaryTournament(pop, len(pop))</a>
<a class="sourceLine" id="cb12-3" title="3">    offspring = crossover_and_mutate(offspring, cxpb, mupb)</a>
<a class="sourceLine" id="cb12-4" title="4">    num_evaluations = evaluate_population(offspring)</a>
<a class="sourceLine" id="cb12-5" title="5">    elitism(pop, offspring)</a>
<a class="sourceLine" id="cb12-6" title="6">    <span class="kw">if</span> mem_strategy <span class="kw">and</span> num_generations % <span class="dv">10</span> == <span class="dv">0</span>:</a>
<a class="sourceLine" id="cb12-7" title="7">        num_evaluations += mem_strategy(population=offspring)</a>
<a class="sourceLine" id="cb12-8" title="8">    pop = offspring</a>
<a class="sourceLine" id="cb12-9" title="9">    return num_evaluations</a>
<a class="sourceLine" id="cb12-10" title="10"></a>
<a class="sourceLine" id="cb12-11" title="11"></a>
<a class="sourceLine" id="cb12-12" title="12"><span class="kw">function</span> stationary_step(pop, cxpb, mupb, mem_strategy, num_generations):</a>
<a class="sourceLine" id="cb12-13" title="13">    offspring = binaryTournament(pop, <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb12-14" title="14">    offspring = crossover_and_mutate(offspring, cxpb, mupb)</a>
<a class="sourceLine" id="cb12-15" title="15">    num_evaluations = evaluate_population(offspring)</a>
<a class="sourceLine" id="cb12-16" title="16">    <span class="kw">if</span> mem_strategy <span class="kw">and</span> num_generations % <span class="dv">10</span> == <span class="dv">0</span>:</a>
<a class="sourceLine" id="cb12-17" title="17">        num_evaluations += mem_strategy(population=offspring)</a>
<a class="sourceLine" id="cb12-18" title="18">    change_worst_ones(pop, offspring)</a>
<a class="sourceLine" id="cb12-19" title="19">    return num_evaluations</a></code></pre></div>
<p>Como vemos, representan los esquemas de evoluci√≥n comentados al principio de la secci√≥n. En cada paso del algoritmo generacional se seleccionan 30 individuos y se aplica elitismo (despu√©s del cruce y mutaci√≥n). Mientras que en el estacionario se seleccionan √∫nicamente dos, y se aplica su reemplazamiento correspondiente.</p>
<p>Estas dos estrategias hacen uso de la funci√≥n <em>crossover_and_mutate</em> que combina y cruza una lista de individuos en base a sus probabilidades correspondientes. El pseudoc√≥digo de esta funci√≥n es el siguiente:</p>
<div class="sourceCode" id="cb13" data-caption="Pseudoc√≥digo del cruce y la mutaci√≥n"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb13-1" title="1"><span class="kw">function</span> crossover_and_mutate(population, cxpb, mutpb):</a>
<a class="sourceLine" id="cb13-2" title="2">    offspring = clone(population)</a>
<a class="sourceLine" id="cb13-3" title="3">    num_crossovers = floor(cxpb * len(offspring))</a>
<a class="sourceLine" id="cb13-4" title="4">    num_mutations = floor(mutpb * len(offspring))</a>
<a class="sourceLine" id="cb13-5" title="5">    <span class="kw">for</span> i = <span class="dv">0</span>..<span class="dv">2</span>..num_crossovers; <span class="kw">do</span></a>
<a class="sourceLine" id="cb13-6" title="6">        offspring[i - <span class="dv">1</span>], offspring[i] = crossover(offspring[i - <span class="dv">1</span>], offspring[i])</a>
<a class="sourceLine" id="cb13-7" title="7">        <span class="co">// Invalida el fitness para calcularlo luego</span></a>
<a class="sourceLine" id="cb13-8" title="8">        delete offspring[i - <span class="dv">1</span>].fitness.values, offspring[i].fitness.values</a>
<a class="sourceLine" id="cb13-9" title="9">    <span class="kw">for</span> i = <span class="dv">0</span>...num_mutations; <span class="kw">do</span></a>
<a class="sourceLine" id="cb13-10" title="10">        offspring[i], mutated = mutate(offspring[i])</a>
<a class="sourceLine" id="cb13-11" title="11">        <span class="kw">if</span> mutated:</a>
<a class="sourceLine" id="cb13-12" title="12">            <span class="co">// Invalida el fitness para calcularlo luego</span></a>
<a class="sourceLine" id="cb13-13" title="13">            delete offspring[i].fitness </a>
<a class="sourceLine" id="cb13-14" title="14">    return offspring</a></code></pre></div>
<p>La √∫ltima funci√≥n clave para el desarrollo de estos algoritmos es la de evaluaci√≥n. La funci√≥n ‚Äúevaluate_population‚Äù se encarga de evaluar aquellos individuos con un fitness nulo. Estos, son individuos que se han generado nuevos a partir de un cruce y/o mutaci√≥n. Para evaluar cada individuo se utiliza la misma funci√≥n fitness que para B√∫squeda Local.</p>
<div class="sourceCode" id="cb14" data-caption="Pseudoc√≥digo de la evaluacion de cromosomas"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb14-1" title="1"><span class="kw">function</span> evaluate_population(population):</a>
<a class="sourceLine" id="cb14-2" title="2">    evaluations = <span class="dv">0</span></a>
<a class="sourceLine" id="cb14-3" title="3">    <span class="kw">for</span> ind <span class="kw">in</span> population; <span class="kw">do</span></a>
<a class="sourceLine" id="cb14-4" title="4">        <span class="kw">if</span> ind.fitness <span class="kw">is</span> null; <span class="kw">do</span></a>
<a class="sourceLine" id="cb14-5" title="5">            ind.fitness = evaluate(ind)</a>
<a class="sourceLine" id="cb14-6" title="6">            evaluations += <span class="dv">1</span></a>
<a class="sourceLine" id="cb14-7" title="7">    return evaluations</a></code></pre></div>
<p>Como vemos, devuelve el numero de evaluaciones de la funci√≥n fitness. Esto sirve para parar la ejecuci√≥n del algoritmo cuando se eval√∫a el fitness un cierto n√∫mero de veces.</p>
<h3 id="toolbox">Toolbox</h3>
<p>Finalmente, hay un concepto que me gustar√≠a explicar que no aparece en el pseudoc√≥digo pero si en la implementaci√≥n. La mayor√≠a de estas funciones, reciben un objeto llamado ‚Äútoolbox‚Äù. Este objeto no es m√°s que un contenedor con todos los operadores que se van a utilizar para el algoritmo. Esto hace que la ejecuci√≥n de un algoritmo evolutivo se pueda abstraer y √∫nicamente haya que crear un ‚Äútoolbox‚Äù con los operadores correspondientes. Esto permite desacoplar el c√≥digo de operadores y funciones de evaluaci√≥n, de la l√≥gica de la estrategia evolutiva. As√≠ por ejemplo, cambiar de operador de selecci√≥n o de cruce, para una misma estrategia (generacional por ej.), es simplemente cambiar un atributo del objeto ‚Äútoolbox‚Äù. Y si queremos cambiar de estrategia basta con indicarle a la funci√≥n ‚Äúrun‚Äù que estrategia queremos.</p>
<h2 id="algoritmos-mem√©ticos">Algoritmos mem√©ticos</h2>
<p>Partiendo de los algoritmos gen√©ticos descritos anteriormente, sabemos que las funciones son gen√©ricas. Si nos fijamos en las estrategias de evoluci√≥n ‚Äúgenerational_step‚Äù y ‚Äústationary_step‚Äù, ambas incluyen un par√°metro para la estrategia mem√©tica. En caso de que le pasemos la estrategia mem√©tica el algoritmo la ejecutar√° cada 10 generaciones.</p>
<p>Para crear la estrategia mem√©tica partimos de la siguiente funci√≥n:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb15-1" title="1"><span class="kw">def</span> memetic_strategy(X, y, max_neighbours, seed, population, num_selected,</a>
<a class="sourceLine" id="cb15-2" title="2">                     prob, sort):</a>
<a class="sourceLine" id="cb15-3" title="3">    <span class="cf">if</span> sort:</a>
<a class="sourceLine" id="cb15-4" title="4">        candidates <span class="op">=</span> tools.selBest(population, num_selected)</a>
<a class="sourceLine" id="cb15-5" title="5">    <span class="cf">else</span>:</a>
<a class="sourceLine" id="cb15-6" title="6">        candidates <span class="op">=</span> population[:num_selected]</a>
<a class="sourceLine" id="cb15-7" title="7">    evaluations <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb15-8" title="8">    <span class="cf">for</span> ind <span class="kw">in</span> candidates:</a>
<a class="sourceLine" id="cb15-9" title="9">        <span class="cf">if</span> random() <span class="op">&lt;</span> prob:</a>
<a class="sourceLine" id="cb15-10" title="10">            new_ind, trace, n_generated <span class="op">=</span> local_search(X, y, max_neighbours,</a>
<a class="sourceLine" id="cb15-11" title="11">                                                       <span class="fl">0.3</span>, seed, ind)</a>
<a class="sourceLine" id="cb15-12" title="12">            evaluations <span class="op">+=</span> n_generated</a>
<a class="sourceLine" id="cb15-13" title="13">            ind <span class="op">=</span> new_ind[:]</a>
<a class="sourceLine" id="cb15-14" title="14">            ind.fitness <span class="op">=</span> trace[<span class="bu">len</span>(trace) <span class="op">-</span> <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb15-15" title="15">    <span class="cf">return</span> evaluations</a></code></pre></div>
<p>Esta funci√≥n puede ejecutar todas las estrategias mem√©ticas de esta pr√°ctica. Por ejemplo, para el algoritmo AM-(1,1.0), usamos prop = 1, num_selected = 10 y sort = False; as√≠ con todos los algoritmos mem√©ticos. Para poder utilizar esta funci√≥n es necesario hacer una aplicaci√≥n parcial y prefijar los argumentos para las diferentes configuraciones. Esto es posible en el lenguaje de programaci√≥n que he utilizado para la implementaci√≥n y por eso he decidido crear una √∫nica funci√≥n ‚Äúplantilla‚Äù de la cual derivar todas las estrategias mem√©ticas.</p>
<p>Como vemos, el desarrollo de estos algoritmos ha sido muy corto debido al uso extensivo de funciones gen√©ricas para los algoritmos anteriores. Lo cu√°l a permitido introducir las estrateg√≠as mem√©ticas sin necesidad de modificar en gran medida el c√≥digo existente.</p>
<h2 id="b√∫squeda-local-reiterada">B√∫squeda Local Reiterada</h2>
<div class="sourceCode" id="cb16" data-caption="Pseudoc√≥digo del algoritmo de B√∫squeda Local Reiterada (ILS)"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb16-1" title="1"><span class="kw">function</span> ils(X, y, iters):</a>
<a class="sourceLine" id="cb16-2" title="2">    init_weights = generate_random_uniform_vector()</a>
<a class="sourceLine" id="cb16-3" title="3">    weights = local_search(X, y, <span class="dv">1000</span>, init_weights)</a>
<a class="sourceLine" id="cb16-4" title="4">    best_fitness = evaluate(weights, X, y)</a>
<a class="sourceLine" id="cb16-5" title="5">    <span class="kw">for</span> i=<span class="dv">0</span>...iters; <span class="kw">do</span></a>
<a class="sourceLine" id="cb16-6" title="6">        candidate = mutate(weights)</a>
<a class="sourceLine" id="cb16-7" title="7">        candidate = local_search(X, y, <span class="dv">1000</span>, candidate)</a>
<a class="sourceLine" id="cb16-8" title="8">        fitness = trace[-<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb16-9" title="9">        <span class="kw">if</span> fitness &gt; best_fitness; <span class="kw">do</span></a>
<a class="sourceLine" id="cb16-10" title="10">            weights = candidate</a>
<a class="sourceLine" id="cb16-11" title="11">            best_fitness = fitness</a>
<a class="sourceLine" id="cb16-12" title="12">    return weights</a></code></pre></div>
<div class="sourceCode" id="cb17" data-caption="Pseudoc√≥digo del operador de mutaci√≥n para ILS"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb17-1" title="1"><span class="kw">function</span> mutate(weights):</a>
<a class="sourceLine" id="cb17-2" title="2">    candidate = copy(weights)</a>
<a class="sourceLine" id="cb17-3" title="3">    N = length(weights)</a>
<a class="sourceLine" id="cb17-4" title="4">    num_comp = N * <span class="dv">0.1</span></a>
<a class="sourceLine" id="cb17-5" title="5">    indices = get_random_indices(N, num_comp)</a>
<a class="sourceLine" id="cb17-6" title="6">    candidate[indices] += generate_gaussian_vector(<span class="dv">0</span>, <span class="dv">0.4</span>, num_comp)</a>
<a class="sourceLine" id="cb17-7" title="7">    candidate = clip(candidate, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb17-8" title="8">    return candidate</a></code></pre></div>
<h2 id="enfriamiento-simulado">Enfriamiento Simulado</h2>
<div class="sourceCode" id="cb18" data-caption="Pseudoc√≥digo del algoritmo de Enfriamiento Simulado"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb18-1" title="1"><span class="kw">function</span> annealing(X, y, max_eval):</a>
<a class="sourceLine" id="cb18-2" title="2">    weights = generate_random_uniform_vector()</a>
<a class="sourceLine" id="cb18-3" title="3">    best_weights = weights</a>
<a class="sourceLine" id="cb18-4" title="4">    fitness = evaluate(best_weights, X, y)</a>
<a class="sourceLine" id="cb18-5" title="5">    best_fitness = fitness</a>
<a class="sourceLine" id="cb18-6" title="6">    T0 = <span class="dv">0.3</span> * best_fitness / (-ln(<span class="dv">0.3</span>))</a>
<a class="sourceLine" id="cb18-7" title="7">    T = T0</a>
<a class="sourceLine" id="cb18-8" title="8">    Tf = clip(<span class="dv">1e-3</span>, <span class="dv">0</span>, T0)</a>
<a class="sourceLine" id="cb18-9" title="9">    evaluations = <span class="dv">0</span></a>
<a class="sourceLine" id="cb18-10" title="10">    accepted = <span class="dv">1</span></a>
<a class="sourceLine" id="cb18-11" title="11">    max_neighbours = <span class="dv">10</span> * length(weights)</a>
<a class="sourceLine" id="cb18-12" title="12">    max_accepted = length(weights)</a>
<a class="sourceLine" id="cb18-13" title="13">    M = max_eval / max_neighbours</a>
<a class="sourceLine" id="cb18-14" title="14">    <span class="kw">while</span> evaluations &lt; max_eval <span class="kw">and</span> accepted &gt; <span class="dv">0</span> <span class="kw">and</span> T &gt; Tf; <span class="kw">do</span></a>
<a class="sourceLine" id="cb18-15" title="15">        accepted = <span class="dv">0</span></a>
<a class="sourceLine" id="cb18-16" title="16">        current_evals = <span class="dv">0</span></a>
<a class="sourceLine" id="cb18-17" title="17">        <span class="kw">while</span> current_evals &lt; max_neighbours <span class="kw">and</span> accepted &lt; max_accepted; <span class="kw">do</span></a>
<a class="sourceLine" id="cb18-18" title="18">            current_evals += <span class="dv">1</span></a>
<a class="sourceLine" id="cb18-19" title="19">            w_prime = mutate(weights)</a>
<a class="sourceLine" id="cb18-20" title="20">            fitness_prime = evaluate(w_prime, X, y)</a>
<a class="sourceLine" id="cb18-21" title="21">            diff = fitness_prime - fitness</a>
<a class="sourceLine" id="cb18-22" title="22">            prob = exp(diff / T)</a>
<a class="sourceLine" id="cb18-23" title="23">            <span class="kw">if</span> diff &gt; <span class="dv">0</span> <span class="kw">or</span> generate_random_uniform_scalar() &lt; prob; <span class="kw">do</span></a>
<a class="sourceLine" id="cb18-24" title="24">                weights = w_prime</a>
<a class="sourceLine" id="cb18-25" title="25">                fitness = fitness_prime</a>
<a class="sourceLine" id="cb18-26" title="26">                accepted += <span class="dv">1</span></a>
<a class="sourceLine" id="cb18-27" title="27">                <span class="kw">if</span> fitness &gt; best_fitness; <span class="kw">do</span></a>
<a class="sourceLine" id="cb18-28" title="28">                    best_fitness = fitness</a>
<a class="sourceLine" id="cb18-29" title="29">                    best_weights = weights</a>
<a class="sourceLine" id="cb18-30" title="30">        evaluations += current_evals</a>
<a class="sourceLine" id="cb18-31" title="31">        beta = (T0 - Tf) / (M * T0 * Tf)</a>
<a class="sourceLine" id="cb18-32" title="32">        T = T / (<span class="dv">1</span> + beta * T)</a>
<a class="sourceLine" id="cb18-33" title="33">    return best_weights </a></code></pre></div>
<div class="sourceCode" id="cb19" data-caption="Pseudoc√≥digo del operador de mutaci√≥n/perturbaci√≥n para Enfriamiento Simulado"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb19-1" title="1"><span class="kw">function</span> mutate(weights):</a>
<a class="sourceLine" id="cb19-2" title="2">    candidate = copy(weights)</a>
<a class="sourceLine" id="cb19-3" title="3">    index = get_random_index(length(weights))</a>
<a class="sourceLine" id="cb19-4" title="4">    perturbation = get_random_normal_scalar(<span class="dv">0</span>, <span class="dv">0.3</span>)</a>
<a class="sourceLine" id="cb19-5" title="5">    candidate[index] = clip(candidate[index] + perturbation, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb19-6" title="6">    return candidate</a></code></pre></div>
<h2 id="evoluci√≥n-diferencial">Evoluci√≥n Diferencial</h2>
<div class="sourceCode" id="cb20" data-caption="Pseudoc√≥digo del algoritmo de Evoluci√≥n Diferencial"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb20-1" title="1"><span class="kw">function</span> de(X, y, iters, strategy, mut, crossp, popsize):</a>
<a class="sourceLine" id="cb20-2" title="2">    N = X.shape[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb20-3" title="3">    pop = np.random.rand(popsize, N)</a>
<a class="sourceLine" id="cb20-4" title="4">    fitness = np.asarray([evaluate(ind, X, y) <span class="kw">for</span> ind <span class="kw">in</span> pop])</a>
<a class="sourceLine" id="cb20-5" title="5">    best_idx = np.argmax(fitness)</a>
<a class="sourceLine" id="cb20-6" title="6">    best = pop[best_idx]</a>
<a class="sourceLine" id="cb20-7" title="7">    <span class="kw">for</span> _ <span class="kw">in</span> range(iters):</a>
<a class="sourceLine" id="cb20-8" title="8">        <span class="kw">for</span> j <span class="kw">in</span> range(popsize):</a>
<a class="sourceLine" id="cb20-9" title="9">            mutant = strategy(best_idx, j, pop, mut)</a>
<a class="sourceLine" id="cb20-10" title="10">            cross_points = np.random.rand(N) &lt; crossp</a>
<a class="sourceLine" id="cb20-11" title="11">            trial = np.where(cross_points, mutant, pop[j])</a>
<a class="sourceLine" id="cb20-12" title="12">            f = evaluate(trial, X, y)</a>
<a class="sourceLine" id="cb20-13" title="13">            <span class="kw">if</span> f &gt; fitness[j]:</a>
<a class="sourceLine" id="cb20-14" title="14">                fitness[j] = f</a>
<a class="sourceLine" id="cb20-15" title="15">                pop[j] = trial</a>
<a class="sourceLine" id="cb20-16" title="16">                <span class="kw">if</span> f &gt; fitness[best_idx]:</a>
<a class="sourceLine" id="cb20-17" title="17">                    best_idx = j</a>
<a class="sourceLine" id="cb20-18" title="18">                    best = trial</a>
<a class="sourceLine" id="cb20-19" title="19">    return best</a></code></pre></div>
<div class="sourceCode" id="cb21" data-caption="Pseudoc√≥digo de los operadores de mutaci√≥n para DE"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb21-1" title="1"><span class="kw">function</span> rand_one(current_idx, pop, mut):</a>
<a class="sourceLine" id="cb21-2" title="2">    indices = permutation(length(pop))[<span class="dv">0</span>:<span class="dv">3</span>]</a>
<a class="sourceLine" id="cb21-3" title="3">    a, b, c = pop[indices]</a>
<a class="sourceLine" id="cb21-4" title="4">    candidate = a + mut * (b - c)</a>
<a class="sourceLine" id="cb21-5" title="5">    return np.clip(candidate, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb21-6" title="6"></a>
<a class="sourceLine" id="cb21-7" title="7"></a>
<a class="sourceLine" id="cb21-8" title="8"><span class="kw">function</span> current_to_best_one(best_idx, current_idx, pop, mut):</a>
<a class="sourceLine" id="cb21-9" title="9">    indices = permutation(length(pop))[<span class="dv">0</span>:<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb21-10" title="10">    a, b = pop[indices]</a>
<a class="sourceLine" id="cb21-11" title="11">    x = pop[current_idx]</a>
<a class="sourceLine" id="cb21-12" title="12">    best = pop[best_idx]</a>
<a class="sourceLine" id="cb21-13" title="13">    candidate = x + mut * (best - x) + mut * (a - b)</a>
<a class="sourceLine" id="cb21-14" title="14">    return clip(candidate, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<h1 id="algoritmo-de-comparaci√≥n">Algoritmo de comparaci√≥n</h1>
<h2 id="relief">Relief</h2>
<p>La implementaci√≥n del algoritmo greedy Relief es bastante sencilla. Para cada muestra en el conjunto de entrenamiento calculamos el amigo (sin contar el mismo) y el enemigo m√°s pr√≥ximos, y actualizamos el vector de pesos con las distancias de cada uno hacia el punto en cuesti√≥n.</p>
<div class="sourceCode" id="cb22" data-caption="Pseudoc√≥digo del algoritmo greedy Relief"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb22-1" title="1"><span class="kw">function</span> relief(X, Y):</a>
<a class="sourceLine" id="cb22-2" title="2">    w = <span class="co">{0, 0,..., 0}</span></a>
<a class="sourceLine" id="cb22-3" title="3">    <span class="kw">for</span> i=<span class="dv">0</span> <span class="kw">to</span> rows_count(X):</a>
<a class="sourceLine" id="cb22-4" title="4">        x, y = X[i], Y[i]</a>
<a class="sourceLine" id="cb22-5" title="5">        X_same_<span class="kw">class</span> = X[Y == y]</a>
<a class="sourceLine" id="cb22-6" title="6">        X_other_<span class="kw">class</span> = X[Y != y]</a>
<a class="sourceLine" id="cb22-7" title="7">        kdtree1 = build_KDTree(X_same_class)</a>
<a class="sourceLine" id="cb22-8" title="8">        kdtree2 = build_KDTree(X_other_class)</a>
<a class="sourceLine" id="cb22-9" title="9">        ally = kdtree1.query(x, k=<span class="dv">2</span>)[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb22-10" title="10">        enemy = kdtree2.query(x, k=<span class="dv">1</span>)[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb22-11" title="11">        ally = X_same_class[ally]</a>
<a class="sourceLine" id="cb22-12" title="12">        enemy = X_other_class[enemy]</a>
<a class="sourceLine" id="cb22-13" title="13">        w += abs(x - enemy) - abs(x - ally)</a>
<a class="sourceLine" id="cb22-14" title="14">    w = clip(w)</a>
<a class="sourceLine" id="cb22-15" title="15">    w = w * (<span class="dv">1</span> / max(w))</a>
<a class="sourceLine" id="cb22-16" title="16">    return w</a></code></pre></div>
<p>Como se puede observar, el algoritmo crea dos √°rboles KDTree en cada iteraci√≥n lo cu√°l no es muy eficiente. El forma ideal ser√≠a crear un √°rbol para cada clase antes del bucle y utilizarlos dentro del bucle, pero el algoritmo de por s√≠ ya es bastante eficiente y por legibilidad del c√≥digo se ha descartado esa opci√≥n.</p>
<h1 id="proceso-de-desarrollo">Proceso de desarrollo</h1>
<p>Para la implementaci√≥n de todos los algoritmos, se ha utilizado <strong>Python3</strong>. Las principales fuentes de informaci√≥n utilizadas para el desarrollo han sido el seminario, el gui√≥n de pr√°cticas y la documentaci√≥n oficial de Python y los diferentes paquetes utilizados.</p>
<p>Con el fin de reutilizar todo el c√≥digo posible, he hecho uso extensivo de la biblioteca de c√°lculo num√©rico y manejo de arrays <strong>Numpy</strong>. Esto ha permitido tener una implementaci√≥n limpia y concisa con una velocidad de ejecuci√≥n aceptable en comparaci√≥n con otros lenguajes como C.</p>
<p>Para la implementaci√≥n de los algoritmos evolutivos se ha utilizado el framework DEAP, que permite de una forma limpia y eficiente implementar todo tipo de estrategias evolutivas. Se ha usado adem√°s para reutilizar algunos operadores como el torneo binario.</p>
<p>Tambi√©n he utilizado algunos <strong>profilers</strong> tanto a nivel de funci√≥n como a nivel de l√≠nea, para detectar los cuellos de botella en el algoritmo de B√∫squeda Local y determinar finalmente que partes hab√≠a que optimizar. Como era de esperar esas partes eran relativas a la funci√≥n fitness, sobre todo calcular la precisi√≥n del clasificador. Por este motivo hice una b√∫squeda sobre las formas m√°s eficientes de calcular los vecinos y encontr√© la estructura de datos <strong>KDTree</strong>. El uso de la misma ha permitido tener una implementaci√≥n m√°s eficiente que usando el t√≠pico algoritmo de fuerza bruta.</p>
<p>Adem√°s, se realizaron algunas pruebas para optimizar el c√≥digo compilando parte del mismo usando Cython, Numba y Pythran las cu√°les, desgraciadamente, no resultaron exitosas y las mejoras que ofrec√≠an no justificaban la complicaci√≥n en cuanto a desarrollo y distribuci√≥n del proyecto.</p>
<p>Finalmente, una vez desarrollado los algoritmos, se envolvieron en una clase con una interfaz similar a los objetos de Scikit-Learn para permitir una integraci√≥n sencilla con el resto del c√≥digo. Con estas dos clases, ya se implement√≥ el programa principal.</p>
<p>El programa principal (<em>practica3.py</em>) tiene varias funcionalidades interesantes. La primera de ellas es la <strong>validaci√≥n en paralelo</strong> de los clasificadores y salida bien formateada de los resultados. El programa una vez obtenidos los resultados genera unos gr√°ficos en formato PNG que se almacenan en la carpeta <strong>output</strong>. Los resultados se pueden tambi√©n exportar en formato ‚Äúxslx‚Äù de Excel. El programa ofrece una validaci√≥n de los argumentos recibidos, as√≠ como una p√°gina de ayuda.</p>
<h1 id="manual-de-usuario"><a href="https://www.antoniomolner.com/practicas_mh_ugr/">Manual de usuario</a></h1>
<p>Antes de continuar con el manual de usuario me gustar√≠a comentar, que debido al crecimiento del proyecto a lo largo de las sesiones de pr√°cticas, me he tomado la molestia de escribir un p√°gina de documentaci√≥n online. En la que se explica de manera estructurada todos los m√≥dulos correspondientes del proyecto, as√≠ como su instalaci√≥n. Puede consultar la documentaci√≥n en este <a href="https://www.antoniomolner.com/practicas_mh_ugr/">sitio</a>. Aunque le recomiendo visitar la documentaci√≥n online, en el resto de secci√≥n tambi√©n se explica como instalar y ejecutar el proyecto.</p>
<p>Para poder ejecutar el proyecto es necesario tener instalado <strong>Python3</strong>. El proyecto no est√° testeado sobre Anaconda aunque posiblemente funcione. √önicamente requiere tener el int√©rprete y el instalador de paquetes <strong>pip</strong> que suele venir por defecto.</p>
<p>El proyecto tiene una serie de dependencias que son necesarias para poder ejecutarlo. Mi recomendaci√≥n es utilizar un entorno virtual de Python para instalar las dependencias y as√≠ no interferir con los paquetes globales. En el directorio del proyecto <strong>FUENTES</strong>, existe un Makefile que crea el entorno virtual e instala los paquetes localmente. Los paquetes a instalar se encuentra en el fichero ‚Äúrequirements.txt‚Äù. La lista es larga pero realmente no se utilizan tantos paquetes expl√≠citamente. Lo que recoge ese archivo son las dependencias y las ‚Äúdependencias de las dependencias‚Äù con sus versiones correspondientes para evitar incompatibilidades.</p>
<p>A efectos pr√°cticos, hay que ejecutar √∫nicamente lo siguiente (dentro del directorio FUENTES):</p>
<div class="sourceCode" id="cb23" data-caption="Ejecuci√≥n del script para instalar las dependencias"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb23-1" title="1"><span class="fu">make</span> install</a>
<a class="sourceLine" id="cb23-2" title="2"><span class="bu">source</span> ./env/bin/activate</a></code></pre></div>
<blockquote>
<p><strong>Nota:</strong> Si se produce un error al instalar el m√≥dulo pykdtree es porque su compilador por defecto no soporta OpenMP. Este error se puede obviar ya que la aplicaci√≥n usar√° otro m√≥dulo en su lugar.</p>
</blockquote>
<p>Una vez instalado todo, ya se puede utilizar el programa principal. Este programa tiene varios par√°metros que se deben especificar: el conjunto de datos, el algoritmo a usar, n√∫mero de procesos a ejecutar en paralelo, etc. En cualquier momento podemos acceder a la ayuda con <strong>-h</strong>.</p>
<div class="sourceCode" id="cb24" data-caption="Salida de la p√°gina de ayuda"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb24-1" title="1"><span class="ex">python3</span> practica2.py -h</a>
<a class="sourceLine" id="cb24-2" title="2"><span class="ex">usage</span>: practica2.py [-h] [--seed SEED] [--n_jobs <span class="dt">{1,2,3,4}</span>] [--trace]</a>
<a class="sourceLine" id="cb24-3" title="3">                    [<span class="ex">--to_excel</span>]</a>
<a class="sourceLine" id="cb24-4" title="4">                    <span class="ex">dataset</span></a>
<a class="sourceLine" id="cb24-5" title="5">                    {<span class="ex">knn</span>,relief,local-search,</a>
<a class="sourceLine" id="cb24-6" title="6">                    <span class="ex">agg-blx</span>,agg-ca,age-blx,age-ca,</a>
<a class="sourceLine" id="cb24-7" title="7">                    <span class="ex">AM-</span>(1,1.0),<span class="ex">AM-</span>(1,0.1),<span class="ex">AM-</span>(1,0.1mej)}</a>
<a class="sourceLine" id="cb24-8" title="8"></a>
<a class="sourceLine" id="cb24-9" title="9"><span class="ex">positional</span> arguments:</a>
<a class="sourceLine" id="cb24-10" title="10">  <span class="ex">dataset</span>               Predefined datasets or a csv file</a>
<a class="sourceLine" id="cb24-11" title="11">  {<span class="ex">knn</span>,relief,local-search,agg-blx,agg-ca,age-blx,age-ca,</a>
<a class="sourceLine" id="cb24-12" title="12">    <span class="ex">AM-</span>(1,1.0),<span class="ex">AM-</span>(1,0.1),<span class="ex">AM-</span>(1,0.1mej)} <span class="ex">Algorithm</span> to use for feature weighting</a>
<a class="sourceLine" id="cb24-13" title="13"></a>
<a class="sourceLine" id="cb24-14" title="14"><span class="ex">optional</span> arguments:</a>
<a class="sourceLine" id="cb24-15" title="15">  <span class="ex">-h</span>, --help            show this help message and exit</a>
<a class="sourceLine" id="cb24-16" title="16">  <span class="ex">--seed</span> SEED           Seed to initialize the random generator (default:</a>
<a class="sourceLine" id="cb24-17" title="17">                        <span class="ex">77766814</span>)</a>
<a class="sourceLine" id="cb24-18" title="18">  <span class="ex">--n_jobs</span> <span class="dt">{1,2,3,4}</span>    Number of jobs to run in parallel to evaluate</a>
<a class="sourceLine" id="cb24-19" title="19">                        <span class="ex">partitions.</span> (default: 1)</a>
<a class="sourceLine" id="cb24-20" title="20">  <span class="ex">--trace</span>               Generate trace for local search (default: False)</a>
<a class="sourceLine" id="cb24-21" title="21">  <span class="ex">--to_excel</span>            Dump results into xlsx file (default: False)</a></code></pre></div>
<p>As√≠, si queremos ejecutar el algoritmo de AM-(1,1.0) con el conjunto de datos Colposcopy, la semilla 1, y en paralelo, ejecutar√≠amos lo siguiente:</p>
<pre data-caption="Salida del programa principal"><code>python3 practica2.py colposcopy &#39;AM-(1,1.0)&#39; --seed=1 --n_jobs=4

    COLPOSCOPY     |     AM-(1,1.0)      |  SEED = 1
=======================================================
             Accuracy  Reduction  Aggregation       Time
Partition 1  0.694915   0.951613     0.823264  10.574860
Partition 2  0.666667   0.935484     0.801075  10.933312
Partition 3  0.631579   0.935484     0.783531  11.138601
Partition 4  0.666667   0.935484     0.801075  10.324892
Partition 5  0.719298   0.951613     0.835456   6.054140

         Accuracy  Reduction  Aggregation       Time
Mean     0.675825   0.941935     0.808880   9.805161
Std.Dev  0.033090   0.008834     0.020479   2.120348
Median   0.666667   0.935484     0.801075  10.574860</code></pre>
<blockquote>
<p><strong>NOTA:</strong> La semilla por defecto es 77766814. Es la semilla utilizada para el an√°lisis de resultados.</p>
</blockquote>
<p>El par√°metro <em>‚Äìtrace</em> es muy interesante ya que puesto a True, permite generar un gr√°fico de como var√≠a la funci√≥n fitness a lo largo de las iteraciones. Obviamente no es aplicable para Relief. Un ejemplo de gr√°fico es el siguiente:</p>
<p><img src="./img/trace.png" /></p>
<p>Adem√°s, la aplicaci√≥n puede leer cualquier archivo <strong>csv</strong>, en el par√°metro dataset √∫nicamente hay que especificar el path del archivo. El √∫nico requisito es que la variable a predecir se encuentre en la √∫ltima columna. Esta variable no hace falta que est√© codificada en enteros, puede ser cualquier variable categ√≥rica, el sistema se encarga de codificarla.</p>
<p>El Makefile contenido dentro del directorio FUENTES tambi√©n sirve para ejecutar todos los algoritmos a la vez:</p>
<div class="sourceCode" id="cb26" data-caption="Ejecuci√≥n de todos los algoritmos"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb26-1" title="1"><span class="fu">make</span> run_all</a></code></pre></div>
<p>GNU Make puede ejecutar varias recetas de forma paralela, pero por defecto lo realiza secuencialmente. Si su procesador es √≥ptimo para el paralelismo, puede ahorrarse tiempo y ejecutar varios algoritmos a la vez:</p>
<div class="sourceCode" id="cb27" data-caption="Ejemplo de paralelizaci√≥n con GNU Make"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb27-1" title="1"><span class="fu">make</span> --jobs=4 run_all</a></code></pre></div>
<h1 id="experimentos-y-an√°lisis-de-resultados">Experimentos y An√°lisis de resultados</h1>
<h2 id="descripci√≥n-de-los-casos-del-problema">Descripci√≥n de los casos del problema</h2>
<p>Los conjuntos de datos utilizados son los siguientes:</p>
<ol type="1">
<li><p><strong>Colposcopy:</strong> Este conjunto de datos tiene 287 muestras y 62 caracter√≠sticas reales extra√≠das de im√°genes colposc√≥picas. El objetivo es clasificar entre positivo y negativo (clasificaci√≥n binaria).</p></li>
<li><p><strong>Ionosphere</strong>: Este conjunto consta de 352 muestras y 34 caracter√≠sticas extra√≠das de datos de radares. Al igual que el conjunto anterior, la variable explicada es categ√≥rica binaria.</p></li>
<li><p><strong>Texture</strong>: Diferentes im√°genes de texturas se han procesado para extraer 550 muestras y 40 atributos. En este caso la clasificaci√≥n es entre 11 categor√≠as distintas.</p></li>
</ol>
<h2 id="resultados-obtenidos">Resultados obtenidos</h2>
<p>Para realizar los experimentos se utilizado una semilla espec√≠fica, mi DNI: 77766814. La semilla se ha utilizado tanto para los algoritmos probabil√≠sticos como para crear las particiones k-fold del conjunto de datos. La funcionalidad de ejecutar la validaci√≥n en paralelo est√° implementada y funciona correctamente, pero se ha utilizado un √∫nico proceso para evaluar todas las particiones y as√≠, obtener tiempos m√≠nimos de cada algoritmo. Los resultados de la ejecuci√≥n de los algoritmos son los siguientes:</p>
<p><embed src="./img/tables.pdf" /></p>
<h2 id="an√°lisis-de-los-resultados">An√°lisis de los resultados</h2>
<p>Antes de continuar con el an√°lisis de los resultados es importante mencionar que las muestras recogidas, pese a haberse obtenido en las mismas condiciones (misma semilla), son bastante peque√±as. Se han realizado √∫nicamente 5 particiones por conjunto de datos, lo que nos da una muestra demasiado peque√±a que nos impide realizar cualquier test de hip√≥tesis param√©trico. Incluso si realiz√°semos un test no param√©trico como el test Anderson-Darling, las conclusiones podr√≠an no ser correctas y podr√≠amos cometer errores de Tipo I o Tipo 2 (falsos positivos o falsos negativos).</p>
<p>Por lo explicado anteriormente, cualquier conclusi√≥n que saquemos con los datos recogidos pueden no ser extrapolables al resto de situaciones. A√∫n as√≠, es importante comparar los resultados para entender que algoritmos funcionan mejor sobre nuestros conjuntos de datos espec√≠ficos y sus particiones correspondientes.</p>
<p>En primer lugar, vemos que el algoritmo 1-NN b√°sico aporta un porcentaje de precisi√≥n alto en los casos <em>Ionosphere</em> y <em>Texture</em> y un porcentaje no tan alto en el conjunto <em>Colposcopy</em>. Si bien la m√©trica de la precisi√≥n puede ser v√°lida en <em>Texture</em>, para los otros dos conjuntos puede no funcionar tan bien. Lo ideal ser√≠a utilizar alguna otra m√©trica como AUC, F1-Score, etc. Pero como nuestro objetivo es comparar diferentes algoritmos que utilizan la misma m√©trica, este detalle no es relevante.</p>
<p>Empezamos hablando del conjunto de datos <strong>Colposcopy.</strong> Sin duda es el conjunto con menor tasa de clasificaci√≥n y reducci√≥n de los tres conjuntos. Para este caso vemos que el clasificador b√°sico tiene una precisi√≥n muy pr√≥xima a la del resto de algoritmos. De hecho, supera en precisi√≥n a todos los algoritmos, excepto a Relief. Para este √∫ltimo, sorprendentemente, en ese conjunto la reducci√≥n es considerable y la precisi√≥n se mantiene con respecto a 1-NN, por tanto, podr√≠amos decir que funciona bastante bien para este dataset en concreto. Para el resto de algoritmos es importante recalcar una cosa. Para b√∫squeda local por ejemplo, la diferencia de precision entre 1-NN y este algoritmo, es de tan solo 3%. Es decir, hemos perdido un 3% de precisi√≥n usando √∫nicamente el 23% de las caracter√≠sticas. Esto implica que nuestro algoritmo posiblemente vaya a generalizar mucho mejor que el clasificador 1-NN y el coste computacional de predecir nuevos valores se va a reducir dr√°sticamente. El inconveniente principal de estos algoritmos en este conjunto de datos (y en general), es el tiempo de ejecuci√≥n. Para obtener los pesos correspondientes tarda de media ~8s (b√∫squeda local), lo cu√°l es bastante mayor que los otros dos algoritmos comparados aunque no es un tiempo desmesurado. Algo similar pasa con los algoritmos evolutivos. Fij√°ndonos ahora en el fitness, los algoritmos gen√©ticos, los estacionarios y los generacionales tienen tasas de agregaci√≥n similares. El √∫nico que destaca es AGG-BLX, pero ni siquiera supera a la b√∫squeda local. Podr√≠amos decir que los los gen√©ticos no funcionan bien en ese conjunto. Otro inconveniente principal es el tiempo que tarda en ejecutarse. Son los algoritmos m√°s lentos. Por otro lado, el algoritmo AM-(1,1.0) tiene un fitness superior a la b√∫squeda local y tarda unos pocos segundos menos que el algoritmo gen√©tico m√°s r√°pido. En cualquiera de los casos, no merece la pena la mejora respecto a BL para el tiempo de ejecuci√≥n que consumen.</p>
<p>Para el conjunto de datos <strong>Ionosphere</strong>, tenemos que la mayor√≠a de algoritmos evolutivos superan o igualan a la b√∫squeda local. Mientras que para Texture, la b√∫squeda local es el algoritmo con mayor tasa de agregaci√≥n. Fij√°ndonos en la tabla general y tomando como referencia los tres conjuntos de datos, dentro de los algoritmos evolutivos, el mejor relaci√≥n fitness-tiempo ser√≠a el algoritmo AM-(1,1.0). Este algoritmo suele tener tasas de agregaci√≥n de las mas altas, y un tiempo de c√≥mputo de los m√°s bajos. Desgraciadamente, los algoritmos evolutivos aqu√≠ implementados se quedan un poco atr√°s con respecto a la b√∫squeda local. La mejora es m√≠nima mientras que el tiempo de c√≥mputo se dispara.</p>
<p>Aunque tampoco hay que ser negativo. Los algoritmos evolutivos tienen varias ventajas respecto a la b√∫squeda local. La primera de ellas, es que se pueden dise√±ar estrategias y operadores espec√≠ficos. Para nuestros algoritmos hemos utilizado operadores y estrategias comunes, pero podr√≠amos adaptarlos a este problema consiguiendo mejoras considerables. Adem√°s, otro factor muy importante es la paralelizaci√≥n. Estos algoritmos evolutivos son muy escalables ya que permiten paralelizar la evaluaci√≥n de los individuos. Esto nos permite aprovechar todo el poder de c√≥mputo de nuestra m√°quina/cluster y poder tener poblaciones m√°s grandes o un n√∫mero mayor de generaciones. En cualquiera de los dos casos, la mejora es considerable. Para b√∫squeda local como cada soluci√≥n depende de la anterior, estamos obligados a ejecutar secuencialmente el c√≥digo.</p>
<p>Lo importante de los algoritmos de APC que estamos implementado es que una vez calculado los pesos √≥ptimos para un conjunto de datos, se validan, y quedan prefijados para el resto del desarrollo. Esto hace que en fases posteriores, realizar predicciones sea mucho m√°s eficiente. Por otra parte, si nuestro objetivo es la inferencia, podemos saber que caracter√≠sticas tienen m√°s importancia que otras cuando nos enfrentamos a algoritmos de aprendizaje ‚Äúblack-box‚Äù, los cuales son dif√≠ciles de interpretar, pero con estos m√©todos podemos desentra√±ar parte de la informaci√≥n que aprenden. Por estos motivos, los altos tiempos de ejecuci√≥n de estos algoritmos, los cu√°les en realidad no son tan altos comparados con t√©cnicas como hyperparametrizaci√≥n, no deben ser limitantes a la hora de usarlo como parte de un flujo de trabajo en Aprendizaje Autom√°tico. Sobre todo, los algoritmos evolutivos que coment√°bamos anteriormente, los cu√°les pueden requerir de mayor potencia de c√≥mputo pero que pueden escalar y encontrar soluciones muy buenas. Al fin y al cabo, es un proceso que se realiza pocas veces en un flujo de trabajo.</p>
<p>Como conclusi√≥n final, podr√≠amos decir que usar una buena implementaci√≥n de estos algoritmos que sea escalable para problemas reales con espacios dimensionales m√°s grandes que los aqu√≠ utilizados, puede ser una buena estrategia para reducir la dimensionalidad del problema, mejorar la eficiencia en predicciones, interpretar modelos ‚Äúblack-box‚Äù o reducir la varianza.</p>
<h2 id="convergencia">Convergencia</h2>
<p>Uno de los aspectos que yo considero relevante para el an√°lisis de un algoritmo es la convergencia. A continuaci√≥n se mostrar√°n unos gr√°ficos de las trazas de los diferentes algoritmos. Para b√∫squeda local se ha utilizado el valor fitness de la soluci√≥n, mientras que en los evolutivos, la traza corresponde al fitness del mejor individuo de la poblaci√≥n a lo largo de las generaciones.</p>
<figure>
<img src="./img/traces1.jpg" alt="Convergencia Algoritmos (1)" /><figcaption>Convergencia Algoritmos (1)</figcaption>
</figure>
<figure>
<img src="./img/traces2.jpg" alt="Convergencia Algoritmos (1)" /><figcaption>Convergencia Algoritmos (1)</figcaption>
</figure>
<figure>
<img src="./img/traces3.jpg" alt="Convergencia Algoritmos (1)" /><figcaption>Convergencia Algoritmos (1)</figcaption>
</figure>
<p>Estos gr√°ficos reflejan la relevancia de las particiones en los conjuntos de datos. Como vemos, el valor de la funci√≥n fitness aumenta r√°pidamente en las primeras iteraciones y posteriormente se estabiliza lo que nos da un indicio de que el algoritmo ha convergido o ronda muy pr√≥ximo a un m√°ximo local. Como vemos en cada partici√≥n se llega a un m√°ximo distinto. Esto es debido a que cada partici√≥n representa un conjunto de datos totalmente distinto y por tanto la funci√≥n fitness tiene una geometr√≠a distinta. En todas las particiones se utiliza el mismo valor de inicializaci√≥n, por tanto el punto de inicio es el mismo para todas las particiones, haciendo que este factor no influya.</p>
<p>Por otra parte vemos que todas las particiones para un mismo algoritmo, siguen la misma tendencia. Es cierto para cada partici√≥n se llega a un m√°ximo distinto, pero la forma con la que llega es similar. Esto nos permite analizar el comportamiento de cada algoritmo y sacar conclusiones independientemente de la semilla o las particiones que se han hecho.</p>
<p>En la <strong>Figura 4</strong>, se puede observar como los algoritmos gen√©ticos difieren bastante en su traza. Para los generacionales, la traza es muy similar a la de la b√∫squeda local. Por otra parte, los algoritmos estacionarios, al seleccionar √∫nicamente dos individuos, requieren de muchas m√°s generaciones para converger.</p>
<p>En la <strong>Figura 5</strong>, vemos como tambi√©n existen diferencias entre los algoritmos mem√©ticos. Para la version AM-(1,1.0), la traza es muy similar a los AGG y a la b√∫squeda local, aunque con saltos m√°s pronunciados. Esto es debido a que se sigue tambi√©n un esquema generacional, pero se mejora toda la poblaci√≥n cada cierto tiempo, haciendo un incremento del fitness del mejor individuo que corresponde con esos saltos pronunciados. Esto se puede observar viendo el gr√°fico donde los saltos corresponden a las generaciones m√∫ltiplo de 10.</p>
<p>Por otro lado, tenemos los algoritmos mem√©ticos donde √∫nicamente se selecciona un individuo. Al igual que los estacionarios, como solo se selecciona un individuo para optimizar mediante b√∫squeda local, el n√∫mero de generaciones aumenta. Y hace que parezca que tarda menos generaciones en converger. Tambi√©n es verdad, que ha efectos del n√∫mero de evaluaciones, estos dos √∫ltimos algoritmos aumentan m√°s r√°pidamente el fitness. Aunque requieran de m√°s generaciones, realmente las evaluaciones de la funci√≥n fitness son muy pocas.</p>
<p>Por √∫ltimo, tenemos los algoritmos implementados en la pr√°ctica 3. Que son ISL, ES, y DE. Como podemos observar, la traza de ILS refleja perfectamente el comportamiento del algoritmo. Esas ca√≠das peri√≥dicas del valor fitness representan la mutaci√≥n que se realiza antes de aplicar la b√∫squeda local. Por otro lado,</p>
<h2 id="an√°lisis-de-tiempos">An√°lisis de tiempos</h2>
<p>Como podemos observar en los resultados, los algoritmos evolutivos tienen un tiempo de ejecuci√≥n mucho mayor que los algoritmos anteriores (b√∫squeda local, relief y 1-NN). Por ese motivo me gustar√≠a analizar en profundidad el motivo de esta diferencia de tiempos.</p>
<p>Tras ejecutar un profiler sobre B√∫squeda local, AGG-BLX, AGE-BLX y AM-(1,1.0) para el conjunto de datos <em>Texture</em>, obtenemos los siguientes resultados:</p>
<figure>
<img src="img/pyinstrument_ls_texture.png" alt="Profiling de B√∫squeda local" /><figcaption>Profiling de B√∫squeda local</figcaption>
</figure>
<figure>
<img src="img/pyinstrument_agg_blx.png" alt="Profiling de AGG-BLX" /><figcaption>Profiling de AGG-BLX</figcaption>
</figure>
<figure>
<img src="img/pyinstrument_age_blx.png" alt="Profiling de AGE-BLX" /><figcaption>Profiling de AGE-BLX</figcaption>
</figure>
<figure>
<img src="img/pyinstrument_am110.png" alt="Profiling de AM-(1,1.0)" /><figcaption>Profiling de AM-(1,1.0)</figcaption>
</figure>
<blockquote>
<p>Nota: Los tiempos son mayores que en una ejecuci√≥n normal por la sobrecarga del profiler.</p>
</blockquote>
<p>Como era de esperar, en todos los casos donde se pasa la mayor parte del tiempo es en la funci√≥n fitness. Para B√∫squeda local, el porcentaje es a√∫n mayor, mientras que para los algoritmos evolutivo tambi√©n hay una parte del tiempo que se emplea en la mutaci√≥n, cruce y el resto de operadores. Pero realmente, la diferencia principal de tiempos recae en el n√∫mero de evaluaciones. Para B√∫squeda local, el criterio de parada hace que nunca lleguemos a evaluar los 15000 vecinos, mientras que con los algoritmos evolutivos esto siempre pasa. Si los algoritmos evolutivos se ejecutasen con el mismo n√∫mero de evaluaciones (efectivas) que el algoritmo de b√∫squeda local, las diferencia de tiempo ser√≠a mucho menor.</p>
<p>Tambi√©n decir que como hemos visto antes, hay una parte irreducible del tiempo. Que es el tiempo que dedica el algoritmo a los distintos operadores. Para la implementaci√≥n que tenemos, los algoritmos evolutivos siempre van a tardar un poco m√°s que la b√∫squeda local. Pero al reducir el n√∫mero de evaluaciones, tambi√©n se reducir√≠a el n√∫mero de cruces, mutaciones, etc. Por lo que la diferencia de tiempos, como he dicho antes, ser√≠a peque√±a. Este tiempo irreducible se ve acentuado en los algoritmos estacionarios. Y es el motivo de que sean m√°s lentos que el resto de algoritmos evolutivos. Como √∫nicamente seleccionan dos hijos, las evaluaciones se disminuyen y aumenta enormemente el n√∫mero de generaciones. Por ese motivo, pr√°cticamente la mitad del tiempo se consume en copiar y operar con los individuos que en la evaluaci√≥n del fitness.</p>
<p>Otro factor tambi√©n a tener en cuenta, es que los algoritmos evolutivos priorizan la <strong>exploraci√≥n</strong> sobre la explotaci√≥n. Si recordamos, nuestra funci√≥n fitness valora de igual medida la reducci√≥n y la precisi√≥n. Esto hace que se eval√∫en constantemente soluciones ‚Äúpeores‚Äù donde la reducci√≥n es peque√±a, comparado con B√∫squeda local, por ejemplo. Esto hace que no se reduzcan muchas caracter√≠sticas al evaluar una soluci√≥n y se tarde m√°s en calcular la precisi√≥n con leave-one-out. Prueba de esto, es la diferencia de tiempos entre los mem√©ticos y los gen√©ticos estacionarios. Ambos eval√∫an la funci√≥n fitness el mismo numero de veces. Sin embargo, los mem√©ticos introducen un factor de explotaci√≥n que hace que r√°pidamente los individuos de las generaciones tenga una reducci√≥n m√°s alta.</p>
<p>Por estos motivos, podemos concluir, para estos conjuntos de datos, que los algoritmos gen√©ticos son los m√°s lentos. Seguidos de los mem√©ticos y de la B√∫squeda local (en dicho orden). Los algoritmos mem√©ticos son m√°s r√°pidos que los gen√©ticos porque eliminan parte de ese tiempo irreducible de aplicar mutaci√≥n, cruce, etc. Y consume m√°s tiempo en la parte de b√∫squeda local, que como bien sabemos es bastante eficiente.</p>
<blockquote>
<p>NOTA: Por tiempo irreducible se entiende aquel que no est√° relacionado directamente con la evaluacion. Es obvio que se puede optimizar esa parte del c√≥digo, pero viendo el profiling, sabemos que el objetivo a optimizar es la funci√≥n fitness. Lo llamamos irreducible porque no se puede eliminar. Por muy √≥ptimo que sea dicha parte, siempre va a acarrear tiempo de c√≥mputo extra comparado con la b√∫squeda local.</p>
</blockquote>
<h1 id="referencias-bibliogr√°ficas">Referencias bibliogr√°ficas</h1>
<h2 id="entendimiento">Entendimiento</h2>
<p>Al principio, pese a lo b√°sico del algoritmo, no llegaba a comprender como funcionaba realmente Relief. Este paper me fue de gran ayuda:</p>
<p><a href="https://www.academia.edu/2675771/RELIEF_Algorithm_and_Similarity_Learning_for_k-NN">RELIEF Algorithm and Similarity Learning for K-NN</a></p>
<h2 id="implementaci√≥n">Implementaci√≥n</h2>
<p>Para la implementaci√≥n he utilizado la documentaci√≥n oficial de Python y sus bibliotecas correspondientes:</p>
<ul>
<li><p><a href="https://docs.python.org/3/index.html">Python3 Docs</a></p></li>
<li><p><a href="https://www.scipy.org/">Scipy-Suite</a></p></li>
<li><p><a href="http://scikit-learn.sourceforge.net/stable/index.html">Scikit-Learn</a></p></li>
<li><p><a href="https://joblib.readthedocs.io/en/latest/">joblib (Paralelismo)</a></p></li>
<li><p><a href="https://stackoverflow.com/questions/48126771/nearest-neighbour-search-kdtree">KDTree</a></p></li>
<li><p><a href="https://deap.readthedocs.io/en/master/index.html">Deap</a></p></li>
</ul>
